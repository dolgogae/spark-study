{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c24e43-1fb2-4c4b-b04a-03859c051d3a",
   "metadata": {},
   "source": [
    "## UDF로 등록하는 의미\n",
    "사용자 정의 함수의 등록: Python으로 작성한 함수를 PySpark의 함수로 등록하여 DataFrame 연산에서 사용할 수 있게 합니다.\n",
    "분산 처리: Spark는 데이터를 분산된 노드에서 처리하므로, UDF는 각 노드에서 실행될 수 있도록 직렬화되고, 노드에서 데이터에 대해 병렬로 적용됩니다.\n",
    "유연성 제공: PySpark의 기본 제공 함수로는 수행할 수 없는 복잡한 로직을 구현하여 데이터 프레임의 각 행에 적용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39ebc1b5-eb60-4876-ace9-dd81d70f0981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100: 217\n",
      "3801: 203\n",
      "2030: 200\n",
      "3021: 191\n",
      "9382: 189\n",
      "+-------------+-----+-----------------+\n",
      "|occupation_id|count|  occupation_name|\n",
      "+-------------+-----+-----------------+\n",
      "|         1100|  217|         engineer|\n",
      "|         3801|  203|          painter|\n",
      "|         2030|  200|        developer|\n",
      "|         3021|  191|chemistry teacher|\n",
      "|         9382|  189|           priest|\n",
      "+-------------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import (\n",
    "    functions as f,\n",
    "    SparkSession,\n",
    "    types as t\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"df_most_interviewed\").getOrCreate()\n",
    "table_schema = t.StructType([\n",
    "    t.StructField(\"interviwer_id\", t.StringType(), False),\n",
    "    t.StructField(\"occupation_id\", t.StringType(), False),\n",
    "    t.StructField(\"rating\", t.IntegerType(), False)])\n",
    "\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/like.csv\"\n",
    "df = spark.read.schema(table_schema).csv(csv_file_path)\n",
    "\n",
    "interviewer_count = df.groupBy(\"occupation_id\").count().orderBy(f.desc(\"count\"))\n",
    "\n",
    "for d in interviewer_count.select(\"occupation_id\", f.col(\"count\").alias(\"cnt\")).collect():\n",
    "    print(f\"{d.occupation_id}: {d.cnt}\")\n",
    "\n",
    "\n",
    "# But, What if we want to know what occupation_id is?  \n",
    "# 1100: engineer\n",
    "# 2030: developer\n",
    "# 3801: painter\n",
    "# 3021: chemistry teacher\n",
    "# 9382: priest\n",
    "\n",
    "meta = {\n",
    "    \"1100\": \"engineer\",\n",
    "    \"2030\": \"developer\",\n",
    "    \"3801\": \"painter\",\n",
    "    \"3021\": \"chemistry teacher\",\n",
    "    \"9382\": \"priest\"\n",
    "}\n",
    "occupation_dict = spark.sparkContext.broadcast(meta)\n",
    "\n",
    "def get_occupation_name(occupation_id: str) -> str:\n",
    "    return occupation_dict.value[occupation_id]\n",
    "\n",
    "occupation_lookup_udf = f.udf(get_occupation_name)\n",
    "\n",
    "occupation_with_name = interviewer_count.withColumn(\"occupation_name\", occupation_lookup_udf(f.col(\"occupation_id\")))\n",
    "\n",
    "occupation_with_name.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
